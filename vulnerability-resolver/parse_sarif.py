import json
import hashlib
from pathlib import Path
from typing import List, Dict, Any, Optional
from collections import defaultdict


class Vulnerability:
    def __init__(self, rule_id: str, cwe: Optional[str], severity: str, 
                 file_path: str, line_number: int, message: str, 
                 fingerprint: str, rule_name: str = ""):
        self.rule_id = rule_id
        self.cwe = cwe
        self.severity = severity
        self.file_path = file_path
        self.line_number = line_number
        self.message = message
        self.fingerprint = fingerprint
        self.rule_name = rule_name
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "rule_id": self.rule_id,
            "rule_name": self.rule_name,
            "cwe": self.cwe,
            "severity": self.severity,
            "file_path": self.file_path,
            "line_number": self.line_number,
            "message": self.message,
            "fingerprint": self.fingerprint
        }
    
    def __repr__(self):
        return f"Vulnerability({self.rule_id}, {self.file_path}:{self.line_number})"


class SARIFParser:
    def __init__(self, sarif_path: str):
        self.sarif_path = Path(sarif_path)
        self.vulnerabilities: List[Vulnerability] = []
        
    def parse(self) -> List[Vulnerability]:
        with open(self.sarif_path, 'r') as f:
            sarif_data = json.load(f)
        
        for run in sarif_data.get('runs', []):
            rules_map = self._build_rules_map(run)
            results = run.get('results', [])
            
            for result in results:
                vuln = self._parse_result(result, rules_map)
                if vuln:
                    self.vulnerabilities.append(vuln)
        
        self.vulnerabilities = self._deduplicate(self.vulnerabilities)
        return self.vulnerabilities
    
    def _build_rules_map(self, run: Dict) -> Dict[str, Dict]:
        rules_map = {}
        
        driver = run.get('tool', {}).get('driver', {})
        for rule in driver.get('rules', []):
            rules_map[rule['id']] = rule
        
        for extension in run.get('tool', {}).get('extensions', []):
            for rule in extension.get('rules', []):
                rules_map[rule['id']] = rule
        
        return rules_map
    
    def _parse_result(self, result: Dict, rules_map: Dict) -> Optional[Vulnerability]:
        rule_id = result.get('ruleId')
        if not rule_id:
            return None
        
        rule_info = rules_map.get(rule_id, {})
        rule_name = rule_info.get('shortDescription', {}).get('text', rule_id)
        
        cwe = self._extract_cwe(rule_info)
        
        level = result.get('level', 'warning')
        severity_map = {
            'error': 'high',
            'warning': 'medium',
            'note': 'low'
        }
        severity = severity_map.get(level, 'medium')
        
        locations = result.get('locations', [])
        if not locations:
            return None
        
        physical_location = locations[0].get('physicalLocation', {})
        artifact_location = physical_location.get('artifactLocation', {})
        file_path = artifact_location.get('uri', 'unknown')
        
        region = physical_location.get('region', {})
        line_number = region.get('startLine', 0)
        
        message = result.get('message', {}).get('text', 'No description')
        
        fingerprint = self._generate_fingerprint(rule_id, file_path, line_number, message)
        
        return Vulnerability(
            rule_id=rule_id,
            cwe=cwe,
            severity=severity,
            file_path=file_path,
            line_number=line_number,
            message=message,
            fingerprint=fingerprint,
            rule_name=rule_name
        )
    
    def _extract_cwe(self, rule_info: Dict) -> Optional[str]:
        tags = rule_info.get('properties', {}).get('tags', [])
        for tag in tags:
            if tag.startswith('external/cwe/'):
                return tag.replace('external/cwe/', '').upper()
        return None
    
    def _generate_fingerprint(self, rule_id: str, file_path: str, 
                             line_number: int, message: str) -> str:
        content = f"{rule_id}:{file_path}:{line_number}:{message}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _deduplicate(self, vulnerabilities: List[Vulnerability]) -> List[Vulnerability]:
        seen_fingerprints = set()
        unique_vulns = []
        
        for vuln in vulnerabilities:
            if vuln.fingerprint not in seen_fingerprints:
                seen_fingerprints.add(vuln.fingerprint)
                unique_vulns.append(vuln)
        
        return unique_vulns


class VulnerabilityBatcher:
    def __init__(self, batch_size: int = 4):
        self.batch_size = batch_size
    
    def create_batches(self, vulnerabilities: List[Vulnerability]) -> List[Dict[str, Any]]:
        if not vulnerabilities:
            return []
        
        batches = []
        remaining = vulnerabilities.copy()
        
        bucket_a_batches = self._bucket_a_batching(remaining)
        batches.extend(bucket_a_batches)
        remaining = [v for v in remaining if not self._is_in_batches(v, bucket_a_batches)]
        
        bucket_b_batches = self._bucket_b_batching(remaining)
        batches.extend(bucket_b_batches)
        remaining = [v for v in remaining if not self._is_in_batches(v, bucket_b_batches)]
        
        bucket_c_batches = self._bucket_c_batching(remaining)
        batches.extend(bucket_c_batches)
        
        return batches
    
    def _bucket_a_batching(self, vulnerabilities: List[Vulnerability]) -> List[Dict[str, Any]]:
        groups = defaultdict(list)
        for vuln in vulnerabilities:
            key = (vuln.file_path, vuln.rule_id)
            groups[key].append(vuln)
        
        batches = []
        for (file_path, rule_id), vulns in groups.items():
            if len(vulns) >= 2:
                for i in range(0, len(vulns), self.batch_size):
                    batch_vulns = vulns[i:i + self.batch_size]
                    batches.append(self._create_batch_metadata(batch_vulns, "bucket_a"))
        
        return batches
    
    def _bucket_b_batching(self, vulnerabilities: List[Vulnerability]) -> List[Dict[str, Any]]:
        groups = defaultdict(list)
        for vuln in vulnerabilities:
            groups[vuln.rule_id].append(vuln)
        
        batches = []
        for rule_id, vulns in groups.items():
            if len(vulns) >= 2:
                for i in range(0, len(vulns), self.batch_size):
                    batch_vulns = vulns[i:i + self.batch_size]
                    batches.append(self._create_batch_metadata(batch_vulns, "bucket_b"))
        
        return batches
    
    def _bucket_c_batching(self, vulnerabilities: List[Vulnerability]) -> List[Dict[str, Any]]:
        groups = defaultdict(list)
        for vuln in vulnerabilities:
            directory = str(Path(vuln.file_path).parent)
            groups[directory].append(vuln)
        
        batches = []
        for directory, vulns in groups.items():
            for i in range(0, len(vulns), self.batch_size):
                batch_vulns = vulns[i:i + self.batch_size]
                batches.append(self._create_batch_metadata(batch_vulns, "bucket_c"))
        
        return batches
    
    def _create_batch_metadata(self, vulnerabilities: List[Vulnerability], 
                              bucket: str) -> Dict[str, Any]:
        files = list(set(v.file_path for v in vulnerabilities))
        issue_types = list(set(v.rule_name for v in vulnerabilities))
        
        pr_title = self._generate_pr_title(issue_types, files)
        
        return {
            "batch_id": hashlib.md5(str([v.fingerprint for v in vulnerabilities]).encode()).hexdigest()[:8],
            "bucket": bucket,
            "pr_title": pr_title,
            "vulnerabilities": [v.to_dict() for v in vulnerabilities],
            "summary": {
                "count": len(vulnerabilities),
                "files": files,
                "issue_types": issue_types,
                "severities": list(set(v.severity for v in vulnerabilities))
            }
        }
    
    def _generate_pr_title(self, issue_types: List[str], files: List[str]) -> str:
        issue_types_str = ", ".join(issue_types[:2])
        if len(issue_types) > 2:
            issue_types_str += f" (+{len(issue_types) - 2} more)"
        
        files_str = ", ".join(files[:3])
        if len(files) > 3:
            files_str += f" (+{len(files) - 3} more)"
        
        return f"CodeQL issue fix: {issue_types_str} in {files_str}"
    
    def _is_in_batches(self, vuln: Vulnerability, batches: List[Dict[str, Any]]) -> bool:
        for batch in batches:
            for batch_vuln in batch['vulnerabilities']:
                if batch_vuln['fingerprint'] == vuln.fingerprint:
                    return True
        return False


def find_most_recent_sarif(directory: str = "codeql-results") -> Optional[str]:
    sarif_dir = Path(directory)
    if not sarif_dir.exists():
        return None
    
    sarif_files = list(sarif_dir.glob("*.sarif"))
    if not sarif_files:
        return None
    
    most_recent = max(sarif_files, key=lambda p: p.stat().st_mtime)
    return str(most_recent)


if __name__ == "__main__":
    import sys
    
    sarif_path = sys.argv[1] if len(sys.argv) > 1 else find_most_recent_sarif()
    
    if not sarif_path:
        print("No SARIF file found")
        sys.exit(1)
    
    print(f"Parsing SARIF file: {sarif_path}")
    parser = SARIFParser(sarif_path)
    vulnerabilities = parser.parse()
    
    print(f"\nFound {len(vulnerabilities)} unique vulnerabilities")
    
    batcher = VulnerabilityBatcher(batch_size=4)
    batches = batcher.create_batches(vulnerabilities)
    
    print(f"Created {len(batches)} batches")
    
    for i, batch in enumerate(batches, 1):
        print(f"\nBatch {i} ({batch['bucket']}):")
        print(f"  PR Title: {batch['pr_title']}")
        print(f"  Vulnerabilities: {batch['summary']['count']}")
        print(f"  Files: {', '.join(batch['summary']['files'])}")
